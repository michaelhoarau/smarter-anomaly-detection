{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa59b25",
   "metadata": {},
   "source": [
    "# **Smarter anomaly detection** - Post-processing back-test results\n",
    "*Part 3 - Results post-processing*\n",
    "\n",
    "## Initialization\n",
    "---\n",
    "This repository is structured as follow:\n",
    "\n",
    "```sh\n",
    ". smarter-anomaly-detection\n",
    "|\n",
    "├── data/\n",
    "|   ├── interim                          # Temporary intermediate data are stored here\n",
    "|   ├── processed                        # Finalized datasets ready to be moved to Amazon S3\n",
    "|   └── raw                              # Immutable original data are stored here\n",
    "|\n",
    "└── notebooks/\n",
    "    ├── 1_data_preparation.ipynb\n",
    "    ├── 2_model_training.ipynb\n",
    "    └── 3_model_evaluation.ipynb         <<< THIS NOTEBOOK <<<\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8532947",
   "metadata": {},
   "source": [
    "### Notebook configuration update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda54c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade lookoutequipment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c71d4a7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import config\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# SDK / toolbox for managing Lookout for Equipment API calls:\n",
    "import lookoutequipment as lookout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ee515",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ede8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DATA       = os.path.join('..', 'data', 'interim')\n",
    "PROCESSED_DATA = os.path.join('..', 'data', 'processed')\n",
    "LABEL_DATA     = os.path.join(PROCESSED_DATA, 'label-data')\n",
    "TRAIN_DATA     = os.path.join(PROCESSED_DATA, 'train-data', 'pump')\n",
    "\n",
    "MODEL_NAME     = config.MODEL_NAME\n",
    "DATASET_NAME   = config.DATASET_NAME\n",
    "ROLE_ARN       = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64782aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "plt.rcParams['lines.linewidth'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2774f805",
   "metadata": {},
   "source": [
    "### Loading original datasets for visualization purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags_fname = os.path.join(TRAIN_DATA, 'sensors.csv')\n",
    "all_tags_df = pd.read_csv(all_tags_fname)\n",
    "all_tags_df['Timestamp'] = pd.to_datetime(all_tags_df['Timestamp'])\n",
    "all_tags_df = all_tags_df.set_index('Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3249e150",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ranges(range_df, range_title, color, ax):\n",
    "    ax.plot(range_df['Label'], color=color)\n",
    "    ax.fill_between(range_df.index, \n",
    "                    y1=range_df['Label'], \n",
    "                    y2=0, \n",
    "                    alpha=0.1, \n",
    "                    color=color)\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    ax.axes.get_yaxis().set_ticks([])\n",
    "    ax.set_xlabel(range_title, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbef5e7",
   "metadata": {},
   "source": [
    "## Extracting model back-test results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd15d5",
   "metadata": {},
   "source": [
    "The [**DescribeModel**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DescribeModel.html) API can be used to extract, among other things, the metrics associated to the trained model. Here are the different fields available when calling this API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3beb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_dataset = lookout.LookoutEquipmentDataset(\n",
    "    dataset_name=DATASET_NAME, \n",
    "    access_role_arn=ROLE_ARN,\n",
    "    component_root_dir=TRAIN_DATA\n",
    ")\n",
    "response = lookout_dataset.client.describe_model(ModelName=MODEL_NAME)\n",
    "training_start   = pd.to_datetime(response['TrainingDataStartTime']).tz_localize(None)\n",
    "training_end     = pd.to_datetime(response['TrainingDataEndTime']).tz_localize(None)\n",
    "evaluation_start = pd.to_datetime(response['EvaluationDataStartTime']).tz_localize(None)\n",
    "evaluation_end   = pd.to_datetime(response['EvaluationDataEndTime']).tz_localize(None)\n",
    "\n",
    "LookoutDiagnostics = lookout.LookoutEquipmentAnalysis(model_name=MODEL_NAME, tags_df=all_tags_df)\n",
    "LookoutDiagnostics.set_time_periods(evaluation_start, evaluation_end, training_start, training_end)\n",
    "predicted_ranges = LookoutDiagnostics.get_predictions()\n",
    "labels_fname = os.path.join(LABEL_DATA, 'labels.csv')\n",
    "labeled_range = LookoutDiagnostics.get_labels(labels_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b512738",
   "metadata": {},
   "source": [
    "## Visualizing anomaly detection model results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc8516",
   "metadata": {},
   "source": [
    "Let's now display one of the original signal and map both the labeled and the predicted ranges on the same plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list = list(all_tags_df.columns)\n",
    "custom_colors = {\n",
    "    'labels': colors[3],\n",
    "    'predictions': colors[1]\n",
    "}\n",
    "    \n",
    "TSViz = lookout.plot.TimeSeriesVisualization(\n",
    "    timeseries_df=all_tags_df,\n",
    "    data_format='tabular'\n",
    ")\n",
    "TSViz.add_signal([tags_list[3]])\n",
    "TSViz.add_labels(labeled_range)\n",
    "TSViz.add_predictions([predicted_ranges])\n",
    "TSViz.add_train_test_split(evaluation_start)\n",
    "TSViz.legend_format = {\n",
    "    'loc': 'upper right',\n",
    "    'framealpha': 0.4,\n",
    "    'ncol': 2\n",
    "}\n",
    "fig, axis = TSViz.plot(fig_width=24, colors=custom_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0c163",
   "metadata": {},
   "source": [
    "Let's zoom on the second part (the big event and some of the spikes happening afterward):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSViz = lookout.plot.TimeSeriesVisualization(\n",
    "    timeseries_df=all_tags_df,\n",
    "    data_format='tabular'\n",
    ")\n",
    "TSViz.add_signal([tags_list[3]])\n",
    "TSViz.add_labels(labeled_range)\n",
    "TSViz.add_predictions([predicted_ranges])\n",
    "TSViz.legend_format = {\n",
    "    'loc': 'upper right',\n",
    "    'framealpha': 0.4,\n",
    "    'ncol': 2\n",
    "}\n",
    "\n",
    "fig, axis = TSViz.plot(fig_width=24, colors=custom_colors)\n",
    "for ax in axis:\n",
    "    ax.set_xlim(pd.to_datetime('2017-08-01'), pd.to_datetime('2018-04-30'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f236b4be",
   "metadata": {},
   "source": [
    "The events are provided as ranges: to further post-process the results, we will need an expanded dataframe where each timestamp is marked as normal or abnormal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de150dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ranges['duration'] = pd.to_datetime(predicted_ranges['end']) - pd.to_datetime(predicted_ranges['start'])\n",
    "predicted_ranges['duration'] = predicted_ranges['duration'].dt.total_seconds() / 3600\n",
    "predictions_df = TSViz._convert_ranges(predicted_ranges, default_freq='5min')\n",
    "predicted_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b52b5f",
   "metadata": {},
   "source": [
    "Let's now expand the results to have one sensor per column in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_results = []\n",
    "for index, row in predicted_ranges.iterrows():\n",
    "    new_row = dict()\n",
    "    new_row.update({'start': row['start']})\n",
    "    new_row.update({'end': row['end']})\n",
    "    new_row.update({'prediction': 1.0})\n",
    "    \n",
    "    diagnostics = pd.DataFrame(row['diagnostics'])\n",
    "    diagnostics = dict(zip(diagnostics['name'], diagnostics['value']))\n",
    "    new_row = {**new_row, **diagnostics}\n",
    "        \n",
    "    expanded_results.append(new_row)\n",
    "    \n",
    "expanded_results = pd.DataFrame(expanded_results)\n",
    "\n",
    "df_list = []\n",
    "for index, row in expanded_results.iterrows():\n",
    "    new_index = pd.date_range(start=row['start'], end=row['end'], freq='5T')\n",
    "    new_df = pd.DataFrame(index=new_index)\n",
    "    \n",
    "    for tag in [t for t in tags_list]:\n",
    "        new_df[tag] = row[f'water-pump\\\\{tag}']\n",
    "        \n",
    "    df_list.append(new_df)\n",
    "    \n",
    "expanded_results_v2 = pd.concat(df_list, axis='index')\n",
    "expanded_results_v2 = expanded_results_v2.reindex(predictions_df.index)\n",
    "\n",
    "freq = '1D'\n",
    "expanded_results_v3 = expanded_results_v2.resample(freq).mean()\n",
    "expanded_results_v3 = expanded_results_v3.replace(to_replace=np.nan, value=0.0)\n",
    "\n",
    "expanded_results_v3.iloc[400:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3bed2",
   "metadata": {},
   "source": [
    "## Results post-processing\n",
    "---\n",
    "### Measuring event rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = pd.to_datetime('2017-08-01')\n",
    "plot_end = pd.to_datetime('2018-04-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343fc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = 'sensor_03'\n",
    "fig = plt.figure(figsize=(24,10))\n",
    "gs = GridSpec(nrows=4, ncols=1, height_ratios=[0.6, 0.3, 0.1, 0.1], hspace=0.35)\n",
    "df = expanded_results_v3.loc[plot_start:plot_end, :].copy()\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0])\n",
    "ax0.plot(all_tags_df.loc[plot_start:plot_end, signal], color=colors[0], linewidth=1.0, label=signal)\n",
    "ax0.legend(loc='upper right', fontsize=12)\n",
    "ax0.set_xlim((plot_start, plot_end))\n",
    "\n",
    "ax1 = fig.add_subplot(gs[1])\n",
    "ax1.plot(predictions_df.rolling(12*24).sum(), label='Number of daily event detected', linewidth=3.0, color=colors[2])\n",
    "ax1.legend(loc='upper right', fontsize=12)\n",
    "ax1.set_xlim((plot_start, plot_end))\n",
    "ax1.axes.get_xaxis().set_ticks([])\n",
    "\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "labels_df = TSViz._convert_ranges(labeled_range, default_freq='5min')\n",
    "plot_ranges(labels_df, 'Known anomalies', colors[3], ax3)\n",
    "ax3.set_xlim((plot_start, plot_end))\n",
    "\n",
    "ax3 = fig.add_subplot(gs[3])\n",
    "plot_ranges(predictions_df, 'Detected events', colors[1], ax3)\n",
    "ax3.set_xlim((plot_start, plot_end))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86733b",
   "metadata": {},
   "source": [
    "### Measuring and plotting variables contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_signals = 50\n",
    "current_tags_list = list(df.sum().sort_values(ascending=False).head(num_top_signals).index)\n",
    "\n",
    "fig = plt.figure(figsize=(24,8))\n",
    "for tag in current_tags_list:\n",
    "    plt.plot(df[tag], linewidth=2.0, label=tag)\n",
    "\n",
    "plt.ylabel('Contribution (%)')\n",
    "plt.title('Sensor contribution evolution over time')\n",
    "plt.legend(loc='lower center', ncol=14, bbox_to_anchor=(0.5, -0.25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e092ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,8))\n",
    "bar_width = 0.8\n",
    "bottom_values = np.zeros((len(df.index),))\n",
    "for tag in current_tags_list:\n",
    "    plt.bar(x=df.index, height=df[tag], bottom=bottom_values, alpha=0.8, width=bar_width, label=tag.split('\\\\')[0])\n",
    "    bottom_values += df[tag].values\n",
    "\n",
    "plt.ylabel('Contribution (%)')\n",
    "plt.title('Sensor contribution evolution over time')\n",
    "plt.legend(loc='lower center', ncol=14, bbox_to_anchor=(0.5, -0.25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,8))\n",
    "num_top_signals = 5\n",
    "bottom_values = np.zeros((len(df.index),))\n",
    "current_tags_list = list(df.sum().sort_values(ascending=False).head(num_top_signals).index)\n",
    "for tag in current_tags_list:\n",
    "    plt.bar(x=df.index, height=df[tag], bottom=bottom_values, alpha=0.8, width=bar_width, label=tag.split('\\\\')[0])\n",
    "    bottom_values += df[tag].values\n",
    "\n",
    "all_other_tags = [t for t in df.columns if t not in current_tags_list]\n",
    "all_other_tags_contrib = df[all_other_tags].sum(axis='columns')\n",
    "plt.bar(x=df.index, height=all_other_tags_contrib, bottom=bottom_values, alpha=0.8, width=bar_width, label=f'All the others\\n({len(all_other_tags)} signals)', color='#CCCCCC')\n",
    "\n",
    "plt.ylabel('Contribution (%)')\n",
    "plt.title('Sensor contribution evolution over time')\n",
    "plt.legend(loc='lower center', ncol=14, bbox_to_anchor=(0.5, -0.15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,16))\n",
    "gs = GridSpec(nrows=4, ncols=1, height_ratios=[0.3, 0.6, 0.1, 0.1], hspace=0.35)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0])\n",
    "ax0.plot(all_tags_df.loc[plot_start:plot_end, signal], color=colors[0], linewidth=1.0, label=signal)\n",
    "ax0.legend(loc='upper right', fontsize=12)\n",
    "ax0.set_xlim((plot_start, plot_end))\n",
    "\n",
    "num_top_signals = 5\n",
    "ax1 = fig.add_subplot(gs[1])\n",
    "bottom_values = np.zeros((len(df.index),))\n",
    "current_tags_list = list(df.sum().sort_values(ascending=False).head(num_top_signals).index)\n",
    "for tag in current_tags_list:\n",
    "    plt.bar(x=df.index, height=df[tag], bottom=bottom_values, alpha=0.8, width=bar_width, label=tag.split('\\\\')[0])\n",
    "    bottom_values += df[tag].values\n",
    "\n",
    "all_other_tags = [t for t in df.columns if t not in current_tags_list]\n",
    "all_other_tags_contrib = df[all_other_tags].sum(axis='columns')\n",
    "plt.bar(x=df.index, height=all_other_tags_contrib, bottom=bottom_values, alpha=0.8, width=bar_width, label=f'All the others\\n({len(all_other_tags)} signals)', color='#CCCCCC')\n",
    "\n",
    "ax1.legend(loc='upper right', ncol=1)\n",
    "ax1.set_xlabel('Signal importance evolution', fontsize=12)\n",
    "ax1.set_xlim((plot_start, plot_end))\n",
    "\n",
    "ax2 = fig.add_subplot(gs[2])\n",
    "labels_df = TSViz._convert_ranges(labeled_range, default_freq='5min')\n",
    "plot_ranges(labels_df, 'Known anomalies', colors[3], ax2)\n",
    "ax2.set_xlim((plot_start, plot_end))\n",
    "\n",
    "ax3 = fig.add_subplot(gs[3])\n",
    "plot_ranges(predictions_df, 'Detected events', colors[1], ax3)\n",
    "ax3.set_xlim((plot_start, plot_end))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045c132",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "In this notebook, you extracted the raw results from the anomaly detection model you trained previously and experimented with a few post-processing techniques to get more insights from your model results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
