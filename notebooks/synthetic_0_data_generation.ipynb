{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0760d35f",
   "metadata": {},
   "source": [
    "# **Smarter anomaly detection** - Generating a synthetic time series dataset\n",
    "*Preliminary part - Synthetic data generation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340928e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "plt.rcParams['lines.linewidth'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47dfc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '2021-01-01 00:00'\n",
    "END   = '2021-12-31 23:55'\n",
    "\n",
    "# Set the frequency using this format in minutes:\n",
    "FREQ = '10min'\n",
    "\n",
    "index = pd.date_range(start=START, end=END, freq=FREQ)\n",
    "df = pd.DataFrame({'timestamp': index})\n",
    "df = df.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e3ca1e",
   "metadata": {},
   "source": [
    "## Base signal generation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5223f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_walk(\n",
    "    num_values,\n",
    "    start_value=0, \n",
    "    step_size=1,\n",
    "    threshold=0.5, \n",
    "    min_value=-np.inf, \n",
    "    max_value=np.inf\n",
    "):\n",
    "    previous_value = start_value\n",
    "    array = np.zeros((num_values,))\n",
    "    for index in range(num_values):\n",
    "        if previous_value < min_value:\n",
    "            previous_value = min_value\n",
    "        if previous_value > max_value:\n",
    "            previous_value = max_value\n",
    "            \n",
    "        probability = random.random()\n",
    "        if probability >= threshold:\n",
    "            array[index] = previous_value + step_size\n",
    "        else:\n",
    "            array[index] = previous_value - step_size\n",
    "            \n",
    "        previous_value = array[index]\n",
    "        \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088674b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TIMESERIES = 20\n",
    "STARTS = np.random.rand(NUM_TIMESERIES,) * 1500 + 100\n",
    "\n",
    "for i in range(NUM_TIMESERIES):\n",
    "    START = STARTS[i]\n",
    "    STEP = abs(STARTS.max() / 2000.0)\n",
    "    MIN = START * 0.9\n",
    "    MAX = START * 1.1\n",
    "    \n",
    "    values = generate_random_walk(df.shape[0], start_value=START, threshold=0.5, step_size=STEP, min_value=MIN, max_value=MAX)\n",
    "    df[f'signal_{i:02}'] = values\n",
    "    \n",
    "fig = plt.figure(figsize=(24,4))\n",
    "plt.plot(df)\n",
    "plt.ylim(0, df.max().max()*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e985b0",
   "metadata": {},
   "source": [
    "## Adding anomalies\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d71e8",
   "metadata": {},
   "source": [
    "### Adding operating modes and anomalies\n",
    "\n",
    "In the next notebook we will train a model over the first **5 months** of the year and evaluate it over the last **7 months**.\n",
    "\n",
    "Based on the underlying signal generated previously, we will introduce the following behaviors:\n",
    "\n",
    "1. *Different operating modes:* we will introduce two different modes in the training periods and introduce a third one in the evaluation periods. The anomaly detection should consider the 3rd mode as an anomaly as it will never have seen it at training time\n",
    "2. *Slow degradation:* we will also introduce a slow degradation on one of the signal in the evaluation period\n",
    "3. *Failure:* after the slow degradation, we will simulate a catastrophic failure where all the signals are reduced to 0.0\n",
    "\n",
    "#### Adding different operating modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_level_shift(series, freq, magnitude_shift, magnitude_multiply=None, start=None, end=None, duration=None):\n",
    "    original_series = series.copy()\n",
    "    # Converting frequency in minutes:\n",
    "    freq = int(freq[:-3])\n",
    "    \n",
    "    if start is None:\n",
    "        ANOMALY_START = original_series.index[int(random.random() * original_series.shape[0] * 0.75)]\n",
    "    else:\n",
    "        ANOMALY_START = start\n",
    "\n",
    "    if (end is None) and (duration is None):\n",
    "        # Durations unit are in number of datapoints. With a frequency of 5 minutes, \n",
    "        # we want to set a minimum duration of:\n",
    "        # 1 week = 7 days x 24 hours x 12 (=60 minutes / 5 minutes)\n",
    "        MIN_DURATION = 60 / freq * 24 * 7\n",
    "        MAX_DURATION = 60 / freq * 24 * 30\n",
    "        ANOMALY_DURATION = MIN_DURATION + int(random.random() * (MAX_DURATION - MIN_DURATION))\n",
    "        ANOMALY_END = ANOMALY_START + relativedelta(minutes=+ANOMALY_DURATION * freq)\n",
    "        \n",
    "    elif end is not None:\n",
    "        ANOMALY_END = end\n",
    "        \n",
    "    elif duration is not None:\n",
    "        ANOMALY_END = ANOMALY_START + relativedelta(minutes=+duration * freq)\n",
    "\n",
    "    index = pd.date_range(ANOMALY_START, ANOMALY_END, freq=f'{freq}min')\n",
    "    anomaly_df = pd.Series(\n",
    "        index=index,\n",
    "        dtype=np.float64\n",
    "    )\n",
    "    anomaly_df.loc[:] = magnitude_shift\n",
    "    \n",
    "    if np.max(index) > np.max(original_series.index):\n",
    "        anomaly_df = anomaly_df[:np.max(original_series.index)]\n",
    "        \n",
    "    if magnitude_multiply is not None:\n",
    "        min_value = original_series[index].min()\n",
    "        avg_value = original_series[index].mean()\n",
    "        original_series[index] -= avg_value\n",
    "        original_series[index] *= magnitude_multiply\n",
    "        original_series[index] += avg_value\n",
    "\n",
    "    new_series = original_series.add(anomaly_df, fill_value=0)\n",
    "    \n",
    "    return new_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198320af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list = list(df.columns)\n",
    "random_tags = random.sample(tags_list, 3)\n",
    "\n",
    "# Adding this mode in training range:\n",
    "level_shift_start = pd.to_datetime('2021-02-01')\n",
    "level_shift_duration = (60 / int(FREQ[:-3])) * 24 * 30\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_level_shift(df[tag], freq=FREQ, magnitude_shift=100, magnitude_multiply=0.5, duration=level_shift_duration, start=level_shift_start)\n",
    "    \n",
    "# Adding a similar mode in the evaluation range\n",
    "level_shift_start = pd.to_datetime('2021-07-01')\n",
    "level_shift_duration = (60 / int(FREQ[:-3])) * 24 * 10\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_level_shift(df[tag], freq=FREQ, magnitude_shift=100, magnitude_multiply=0.5, duration=level_shift_duration, start=level_shift_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8578b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_tags = random_tags\n",
    "random_tags = random.sample(tags_list, 5)\n",
    "used_tags = used_tags + random_tags\n",
    "\n",
    "# Adding this mode only in the evaluation range:\n",
    "level_shift_start = pd.to_datetime('2021-09-01')\n",
    "level_shift_duration = (60 / int(FREQ[:-3])) * 24 * 5\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_level_shift(df[tag], freq=FREQ, magnitude_shift=+250, magnitude_multiply=2.5, duration=level_shift_duration, start=level_shift_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6face82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,4))\n",
    "for tag in df.columns:\n",
    "    if tag in used_tags:\n",
    "        plt.plot(df[tag], linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(df[tag], alpha=0.4, linewidth=0.5)\n",
    "    \n",
    "plt.ylim(0.0, df.max().max()*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31e127",
   "metadata": {},
   "source": [
    "#### Slow degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_degradation(series, freq, start=None, end=None, duration=None, degradation_speed=0.05, degradation_slope=-0.05, degradation_duration=None):\n",
    "    original_series = series.copy()\n",
    "    # Converting frequency in minutes:\n",
    "    freq = int(freq[:-3])\n",
    "    \n",
    "    if start is None:\n",
    "        ANOMALY_START = original_series.index[int(random.random() * original_series.shape[0] * 0.75)]\n",
    "    else:\n",
    "        ANOMALY_START = start\n",
    "\n",
    "    if (end is None) and (duration is None):\n",
    "        # Durations unit are in number of datapoints. With a frequency of 5 minutes, \n",
    "        # we want to set a minimum duration of:\n",
    "        # 1 week = 7 days x 24 hours x 12 (=60 minutes / 5 minutes)\n",
    "        MIN_DURATION = 60 / freq * 24 * 7\n",
    "        MAX_DURATION = 60 / freq * 24 * 30\n",
    "        ANOMALY_DURATION = MIN_DURATION + int(random.random() * (MAX_DURATION - MIN_DURATION))\n",
    "        ANOMALY_END = ANOMALY_START + relativedelta(minutes=+ANOMALY_DURATION * freq)\n",
    "        \n",
    "    elif end is not None:\n",
    "        ANOMALY_END = end\n",
    "        \n",
    "    elif duration is not None:\n",
    "        ANOMALY_END = ANOMALY_START + relativedelta(minutes=+duration * freq)\n",
    "        ANOMALY_DURATION = duration\n",
    "\n",
    "    values = generate_random_walk(ANOMALY_DURATION + 1, start_value=0.0, threshold=0.5 - degradation_slope, step_size=degradation_speed)\n",
    "    index = pd.date_range(ANOMALY_START, ANOMALY_END, freq=f'{freq}min')\n",
    "    anomaly_df = pd.Series(index=index, dtype=np.float64)\n",
    "    \n",
    "    anomaly_df.loc[:] = values\n",
    "    \n",
    "    last_value = values[-1]\n",
    "    end_signal = pd.DataFrame(\n",
    "        index=pd.date_range(ANOMALY_END, np.max(df.index), freq=f'{freq}min')\n",
    "    )\n",
    "    \n",
    "    original_series.loc[ANOMALY_END + relativedelta(minutes=+freq):] = series.loc[ANOMALY_END:] + last_value\n",
    "    \n",
    "    if degradation_duration is not None:\n",
    "        DEGRADATION_END = ANOMALY_END + relativedelta(minutes=+degradation_duration * freq)\n",
    "        original_series.loc[DEGRADATION_END:] = series.loc[DEGRADATION_END:]\n",
    "    \n",
    "    new_series = original_series.add(anomaly_df, fill_value=0)\n",
    "    \n",
    "    return new_series, anomaly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd22c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_tags = [t for t in df.columns if t not in used_tags]\n",
    "random_tags = random.sample(unused_tags, 2)\n",
    "tag1, tag2 = random_tags[0], random_tags[1]\n",
    "\n",
    "df[tag1], anomaly_series_train = add_degradation(df[tag1], FREQ, start=pd.to_datetime('2021-03-15'), duration=int(60/int(FREQ[:-3]))*24*15, degradation_speed=1.0, degradation_slope=0.03, degradation_duration=(60/int(FREQ[:-3]))*24*7)\n",
    "df[tag2], anomaly_series_eval = add_degradation(df[tag2], FREQ, start=pd.to_datetime('2021-10-01'), duration=int(60/int(FREQ[:-3]))*24*30, degradation_speed=1.0, degradation_slope=0.03, degradation_duration=(60/int(FREQ[:-3]))*24*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,4))\n",
    "for tag in tags_list:\n",
    "    if tag in random_tags:\n",
    "        plt.plot(df[tag], label=tag, linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(df[tag], label=tag, linewidth=0.5, alpha=0.5)\n",
    "\n",
    "plt.ylim(df.min().min(), df.max().max()*1.1)\n",
    "plt.legend(ncol=len(tags_list), loc='upper left', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f534c",
   "metadata": {},
   "source": [
    "#### Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_failure(series, start, duration, freq):\n",
    "    freq = int(freq[:-3])\n",
    "    original_series = series.copy()\n",
    "    ANOMALY_START = start\n",
    "    ANOMALY_DURATION = duration\n",
    "    index = pd.date_range(ANOMALY_START, periods=ANOMALY_DURATION, freq=f'{freq}min')\n",
    "\n",
    "    original_series.loc[index] = 0.0\n",
    "    \n",
    "    return original_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22752f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tags = random.sample(tags_list, 6)\n",
    "used_tags = random_tags\n",
    "failure_duration = (60/int(FREQ[:-3]))*24*5\n",
    "failure_start = np.max(anomaly_series_train.index) + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*7)\n",
    "\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_failure(df[tag], freq=FREQ, duration=failure_duration, start=failure_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tags = random.sample(tags_list, 8)\n",
    "used_tags = used_tags + random_tags\n",
    "failure_duration = (60/int(FREQ[:-3]))*24*10\n",
    "failure_start = np.max(anomaly_series_eval.index) + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*10)\n",
    "\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_failure(df[tag], freq=FREQ, duration=failure_duration, start=failure_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d2ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,4))\n",
    "for tag in df.columns:\n",
    "    if tag in used_tags:\n",
    "        plt.plot(df[tag], linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(df[tag], linewidth=0.5, alpha=0.5)\n",
    "    \n",
    "plt.ylim(-10.0, df.max().max()*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09130511",
   "metadata": {},
   "source": [
    "### Recording the failures in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['machine_status'] = 'NORMAL'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d04d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_start = np.max(anomaly_series_train.index) + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*7)\n",
    "recovering_start = failure_start + relativedelta(minutes=+int(FREQ[:-3]))\n",
    "recovering_end = recovering_start + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*5)\n",
    "df.loc[failure_start, 'machine_status'] = 'BROKEN'\n",
    "df.loc[recovering_start:recovering_end, 'machine_status'] = 'RECOVERING'\n",
    "\n",
    "failure_start = np.max(anomaly_series_eval.index) + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*10)\n",
    "recovering_start = failure_start + relativedelta(minutes=+int(FREQ[:-3]))\n",
    "recovering_end = recovering_start + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*10)\n",
    "df.loc[failure_start, 'machine_status'] = 'BROKEN'\n",
    "df.loc[recovering_start:recovering_end, 'machine_status'] = 'RECOVERING'\n",
    "\n",
    "fig = plt.figure(figsize=(24,4))\n",
    "plt.plot(df['machine_status'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed13a72",
   "metadata": {},
   "source": [
    "## Saving the dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce99df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('..', 'data', 'interim', 'synthetic'), exist_ok=True)\n",
    "tags_fname = os.path.join('..', 'data', 'interim', 'synthetic', 'sensors.csv')\n",
    "df.to_csv(tags_fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
