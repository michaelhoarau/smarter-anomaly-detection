{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47438a8",
   "metadata": {},
   "source": [
    "# **Smarter anomaly detection** - Generating a synthetic time series dataset\n",
    "*Preliminary part - Synthetic data generation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd95858",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "plt.rcParams['lines.linewidth'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bfa5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '2021-01-01 00:00'\n",
    "END   = '2021-12-31 23:50'\n",
    "\n",
    "# Set the frequency using this format in minutes:\n",
    "FREQ = '10min'\n",
    "\n",
    "index = pd.date_range(start=START, end=END, freq=FREQ)\n",
    "df = pd.DataFrame({'timestamp': index})\n",
    "df = df.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe758de",
   "metadata": {},
   "source": [
    "## Base signal generation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65cd17",
   "metadata": {},
   "source": [
    "### Random signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ca452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = np.random.normal(0, 1, len(index))\n",
    "\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "plt.plot(df)\n",
    "plt.title('Random values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c0ba7",
   "metadata": {},
   "source": [
    "### Leveraging a random walk process\n",
    "#### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_walk(\n",
    "    num_values,\n",
    "    start=0, \n",
    "    step=1,\n",
    "    probability=0.5, \n",
    "    min_value=-np.inf, \n",
    "    max_value=np.inf\n",
    "):\n",
    "    previous_value = start\n",
    "    array = np.zeros((num_values,))\n",
    "    for index in range(num_values):\n",
    "        if previous_value < min_value:\n",
    "            previous_value = min_value\n",
    "        if previous_value > max_value:\n",
    "            previous_value = max_value\n",
    "            \n",
    "        p = random.random()\n",
    "        if p >= probability:\n",
    "            array[index] = previous_value + step\n",
    "        else:\n",
    "            array[index] = previous_value - step\n",
    "            \n",
    "        previous_value = array[index]\n",
    "        \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cadfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,16))\n",
    "ax = fig.add_subplot(3,1,1)\n",
    "ax.plot(generate_random_walk(df.shape[0]))\n",
    "ax.set_title('Example 1')\n",
    "\n",
    "ax = fig.add_subplot(3,1,2)\n",
    "ax.plot(generate_random_walk(df.shape[0], probability=0.49), label='Bias toward increasing values', color=colors[1])\n",
    "ax.plot(generate_random_walk(df.shape[0], probability=0.51), label='Bias toward increasing values', color=colors[2])\n",
    "ax.legend()\n",
    "ax.set_title('Example 2')\n",
    "\n",
    "ax = fig.add_subplot(3,1,3)\n",
    "ax.plot(generate_random_walk(df.shape[0], probability=0.5, start=100, min_value=90, max_value=150), label='Evolving around 100', color=colors[3])\n",
    "ax.plot(generate_random_walk(df.shape[0], probability=0.5, start=-150, min_value=-200, max_value=-120), label='Evolving around -150', color=colors[4])\n",
    "ax.legend()\n",
    "ax.set_ylim(-240, 160)\n",
    "ax.set_title('Example 3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928df20",
   "metadata": {},
   "source": [
    "#### Generating a multivariate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TIMESERIES = 20\n",
    "STARTS = np.random.rand(NUM_TIMESERIES,) * 1500 + 100\n",
    "\n",
    "df = df.drop('value', axis='columns')\n",
    "for i in range(NUM_TIMESERIES):\n",
    "    START = STARTS[i]\n",
    "    STEP = abs(STARTS.max() / 2000.0)\n",
    "    MIN = START * 0.9\n",
    "    MAX = START * 1.1\n",
    "    \n",
    "    values = generate_random_walk(\n",
    "        df.shape[0], \n",
    "        start=START, \n",
    "        probability=0.5, \n",
    "        step=STEP, \n",
    "        min_value=MIN, \n",
    "        max_value=MAX\n",
    "    )\n",
    "    df[f'signal_{i:02}'] = values\n",
    "    \n",
    "fig = plt.figure(figsize=(24,8))\n",
    "plt.plot(df)\n",
    "plt.ylim(0, df.max().max()*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7509c8d",
   "metadata": {},
   "source": [
    "## Adding anomalies\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8259cf32",
   "metadata": {},
   "source": [
    "### Adding operating modes and anomalies\n",
    "\n",
    "In the next notebook we will train a model over the first **5 months** of the year and evaluate it over the last **7 months**.\n",
    "\n",
    "Based on the underlying signal generated previously, we will introduce the following behaviors:\n",
    "\n",
    "1. *Different operating modes:* we will introduce two different modes in the training periods and introduce a third one in the evaluation periods. The anomaly detection should consider the 3rd mode as an anomaly as it will never have seen it at training time\n",
    "2. *Slow degradation:* we will also introduce a slow degradation on one of the signal in the evaluation period\n",
    "3. *Failure:* after the slow degradation, we will simulate a catastrophic failure where all the signals are reduced to 0.0\n",
    "\n",
    "#### Adding different operating modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddcb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_level_shift(series, freq, magnitude_shift, magnitude_multiply=None, start=None, end=None, duration=None):\n",
    "    original_series = series.copy()\n",
    "    # Converting frequency in minutes:\n",
    "    freq = int(freq[:-3])\n",
    "    \n",
    "    if start is None:\n",
    "        ANOMALY_START = original_series.index[int(random.random() * original_series.shape[0] * 0.75)]\n",
    "    else:\n",
    "        ANOMALY_START = start\n",
    "\n",
    "    if (end is None) and (duration is None):\n",
    "        # Durations unit are in number of datapoints. With a frequency of 5 minutes, \n",
    "        # we want to set a minimum duration of:\n",
    "        # 1 week = 7 days x 24 hours x 12 (=60 minutes / 5 minutes)\n",
    "        MIN_DURATION = 60 / freq * 24 * 7\n",
    "        MAX_DURATION = 60 / freq * 24 * 30\n",
    "        ANOMALY_DURATION = MIN_DURATION + int(random.random() * (MAX_DURATION - MIN_DURATION))\n",
    "        ANOMALY_END = ANOMALY_START + relativedelta(minutes=+ANOMALY_DURATION * freq)\n",
    "        \n",
    "    elif end is not None:\n",
    "        ANOMALY_END = end\n",
    "        \n",
    "    elif duration is not None:\n",
    "        ANOMALY_END = ANOMALY_START + relativedelta(minutes=+duration * freq)\n",
    "\n",
    "    index = pd.date_range(ANOMALY_START, ANOMALY_END, freq=f'{freq}min')\n",
    "    anomaly_df = pd.Series(\n",
    "        index=index,\n",
    "        dtype=np.float64\n",
    "    )\n",
    "    anomaly_df.loc[:] = magnitude_shift\n",
    "    \n",
    "    if np.max(index) > np.max(original_series.index):\n",
    "        anomaly_df = anomaly_df[:np.max(original_series.index)]\n",
    "        \n",
    "    if magnitude_multiply is not None:\n",
    "        min_value = original_series[index].min()\n",
    "        avg_value = original_series[index].mean()\n",
    "        original_series[index] -= avg_value\n",
    "        original_series[index] *= magnitude_multiply\n",
    "        original_series[index] += avg_value\n",
    "\n",
    "    new_series = original_series.add(anomaly_df, fill_value=0)\n",
    "    \n",
    "    return new_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa766a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list = list(df.columns)\n",
    "tag = tags_list[0]\n",
    "\n",
    "level_shift_start = pd.to_datetime('2021-02-01')\n",
    "level_shift_duration = (60 / int(FREQ[:-3])) * 24 * 30\n",
    "new_tag = add_level_shift(df[tag], freq=FREQ, magnitude_shift=100, magnitude_multiply=0.5, duration=level_shift_duration, start=level_shift_start)\n",
    "fig = plt.figure(figsize=(24,8))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.plot(df[tag], linewidth=1.0, label='Original signal')\n",
    "ax.plot(new_tag, linewidth=5.0, alpha=0.5, label='Signal with level shift')\n",
    "ax.legend()\n",
    "\n",
    "level_shift_start = pd.to_datetime('2021-07-01')\n",
    "level_shift_duration = (60 / int(FREQ[:-3])) * 24 * 60\n",
    "new_tag = add_level_shift(df[tag], freq=FREQ, magnitude_shift=-100, magnitude_multiply=4.0, duration=level_shift_duration, start=level_shift_start)\n",
    "ax = fig.add_subplot(2, 1, 2)\n",
    "ax.plot(df[tag], linewidth=1.0, label='Original signal')\n",
    "ax.plot(new_tag, linewidth=5.0, alpha=0.5, label='Signal with level shift')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee7d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list = list(df.columns)\n",
    "random_tags = random.sample(tags_list, 3)\n",
    "\n",
    "# Adding this mode in training range:\n",
    "level_shift_start = pd.to_datetime('2021-02-01')\n",
    "level_shift_duration = (60 / int(FREQ[:-3])) * 24 * 30\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_level_shift(df[tag], freq=FREQ, magnitude_shift=100, magnitude_multiply=0.5, duration=level_shift_duration, start=level_shift_start)\n",
    "    \n",
    "# Adding a similar mode in the evaluation range\n",
    "level_shift_start = pd.to_datetime('2021-07-01')\n",
    "level_shift_duration = (60 / int(FREQ[:-3])) * 24 * 10\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_level_shift(df[tag], freq=FREQ, magnitude_shift=100, magnitude_multiply=0.5, duration=level_shift_duration, start=level_shift_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_tags = random_tags\n",
    "random_tags = random.sample(tags_list, 5)\n",
    "used_tags = used_tags + random_tags\n",
    "\n",
    "# Adding this mode only in the evaluation range:\n",
    "level_shift_start = pd.to_datetime('2021-09-01')\n",
    "level_shift_duration = (60 / int(FREQ[:-3])) * 24 * 5\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_level_shift(df[tag], freq=FREQ, magnitude_shift=+250, magnitude_multiply=2.5, duration=level_shift_duration, start=level_shift_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac768d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,8))\n",
    "for tag in df.columns:\n",
    "    if tag in used_tags:\n",
    "        plt.plot(df[tag], linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(df[tag], alpha=0.4, linewidth=0.5)\n",
    "    \n",
    "plt.ylim(0.0, df.max().max()*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f9764",
   "metadata": {},
   "source": [
    "#### Slow degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f61f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_degradation(\n",
    "    series, \n",
    "    freq, \n",
    "    start=None, \n",
    "    end=None, \n",
    "    duration=None, \n",
    "    degradation_speed=0.05, \n",
    "    degradation_slope=-0.05, \n",
    "    degradation_duration=None\n",
    "):\n",
    "    original_series = series.copy()\n",
    "    \n",
    "    # Converting frequency in minutes:\n",
    "    freq = int(freq[:-3])\n",
    "    \n",
    "    # Defines the start of the anomaly:\n",
    "    if start is None:\n",
    "        ANOMALY_START = original_series.index[int(random.random() * original_series.shape[0] * 0.75)]\n",
    "    else:\n",
    "        ANOMALY_START = start\n",
    "\n",
    "    # Defines the end and the duration:\n",
    "    if (end is None) and (duration is None):\n",
    "        # Durations unit are in number of datapoints. With a frequency of 5 minutes, \n",
    "        # we want to set a minimum duration of:\n",
    "        # 1 week = 7 days x 24 hours x 12 (=60 minutes / 5 minutes)\n",
    "        MIN_DURATION = 60 / freq * 24 * 7\n",
    "        MAX_DURATION = 60 / freq * 24 * 30\n",
    "        ANOMALY_DURATION = MIN_DURATION + int(random.random() * (MAX_DURATION - MIN_DURATION))\n",
    "        ANOMALY_END = ANOMALY_START + relativedelta(minutes=+ANOMALY_DURATION * freq)\n",
    "        \n",
    "    elif end is not None:\n",
    "        ANOMALY_END = end\n",
    "        \n",
    "    elif duration is not None:\n",
    "        ANOMALY_END = ANOMALY_START + relativedelta(minutes=+duration * freq)\n",
    "        ANOMALY_DURATION = duration\n",
    "\n",
    "    # Generates a new random walk for the anomaly:\n",
    "    values = generate_random_walk(\n",
    "        ANOMALY_DURATION + 1, \n",
    "        start=0.0, \n",
    "        probability=0.5 - degradation_slope, \n",
    "        step=degradation_speed\n",
    "    )\n",
    "    index = pd.date_range(ANOMALY_START, ANOMALY_END, freq=f'{freq}min')\n",
    "    anomaly_df = pd.Series(index=index, dtype=np.float64)\n",
    "    anomaly_df.loc[:] = values\n",
    "    \n",
    "    # Add \n",
    "    last_value = values[-1]\n",
    "    original_series.loc[ANOMALY_END + relativedelta(minutes=+freq):] = series.loc[ANOMALY_END:] + last_value\n",
    "    \n",
    "    if degradation_duration is not None:\n",
    "        DEGRADATION_END = ANOMALY_END + relativedelta(minutes=+degradation_duration * freq)\n",
    "        original_series.loc[DEGRADATION_END:] = series.loc[DEGRADATION_END:]\n",
    "    \n",
    "    new_series = original_series.add(anomaly_df, fill_value=0)\n",
    "    \n",
    "    return new_series, anomaly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_tags = [t for t in df.columns if t not in used_tags]\n",
    "random_tags = random.sample(unused_tags, 2)\n",
    "tag1, tag2 = random_tags[0], random_tags[1]\n",
    "\n",
    "df[tag1], anomaly_series_train = add_degradation(df[tag1], FREQ, start=pd.to_datetime('2021-03-15'), duration=int(60/int(FREQ[:-3]))*24*15, degradation_speed=1.0, degradation_slope=0.03, degradation_duration=(60/int(FREQ[:-3]))*24*7)\n",
    "df[tag2], anomaly_series_eval = add_degradation(df[tag2], FREQ, start=pd.to_datetime('2021-10-01'), duration=int(60/int(FREQ[:-3]))*24*30, degradation_speed=1.0, degradation_slope=0.03, degradation_duration=(60/int(FREQ[:-3]))*24*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,8))\n",
    "for tag in tags_list:\n",
    "    if tag in random_tags:\n",
    "        plt.plot(df[tag], label=tag, linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(df[tag], label=tag, linewidth=0.5, alpha=0.5)\n",
    "\n",
    "plt.ylim(df.min().min(), df.max().max()*1.1)\n",
    "# plt.legend(ncol=len(tags_list), loc='upper left', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c216ed",
   "metadata": {},
   "source": [
    "#### Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeab1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_failure(series, start, duration, freq):\n",
    "    freq = int(freq[:-3])\n",
    "    original_series = series.copy()\n",
    "    ANOMALY_START = start\n",
    "    ANOMALY_DURATION = duration\n",
    "    index = pd.date_range(ANOMALY_START, periods=ANOMALY_DURATION, freq=f'{freq}min')\n",
    "\n",
    "    original_series.loc[index] = 0.0\n",
    "    \n",
    "    return original_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d28c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tags = random.sample(tags_list, 6)\n",
    "used_tags = random_tags\n",
    "failure_duration = (60/int(FREQ[:-3]))*24*5\n",
    "failure_start = np.max(anomaly_series_train.index) + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*7)\n",
    "\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_failure(df[tag], freq=FREQ, duration=failure_duration, start=failure_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad882e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tags = random.sample(tags_list, 8)\n",
    "used_tags = used_tags + random_tags\n",
    "failure_duration = (60/int(FREQ[:-3]))*24*10\n",
    "failure_start = np.max(anomaly_series_eval.index) + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*10)\n",
    "\n",
    "for tag in random_tags:\n",
    "    df[tag] = add_failure(df[tag], freq=FREQ, duration=failure_duration, start=failure_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,8))\n",
    "for tag in df.columns:\n",
    "    if tag in used_tags:\n",
    "        plt.plot(df[tag], linewidth=2.0)\n",
    "    else:\n",
    "        plt.plot(df[tag], linewidth=0.5, alpha=0.5)\n",
    "    \n",
    "plt.ylim(-10.0, df.max().max()*1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3ba50",
   "metadata": {},
   "source": [
    "### Recording the failures in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['machine_status'] = 'NORMAL'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_start = np.max(anomaly_series_train.index) + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*7)\n",
    "recovering_start = failure_start + relativedelta(minutes=+int(FREQ[:-3]))\n",
    "recovering_end = recovering_start + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*5)\n",
    "df.loc[failure_start, 'machine_status'] = 'BROKEN'\n",
    "df.loc[recovering_start:recovering_end, 'machine_status'] = 'RECOVERING'\n",
    "\n",
    "failure_start = np.max(anomaly_series_eval.index) + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*10)\n",
    "recovering_start = failure_start + relativedelta(minutes=+int(FREQ[:-3]))\n",
    "recovering_end = recovering_start + relativedelta(minutes=+int(FREQ[:-3]) * (60/int(FREQ[:-3]))*24*10)\n",
    "df.loc[failure_start, 'machine_status'] = 'BROKEN'\n",
    "df.loc[recovering_start:recovering_end, 'machine_status'] = 'RECOVERING'\n",
    "\n",
    "fig = plt.figure(figsize=(24,4))\n",
    "plt.plot(df['machine_status'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eaa5de",
   "metadata": {},
   "source": [
    "## Saving the dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523eb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('..', 'data', 'interim', 'synthetic'), exist_ok=True)\n",
    "tags_fname = os.path.join('..', 'data', 'interim', 'synthetic', 'sensors.csv')\n",
    "df.to_csv(tags_fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
